name,modelType,num_layer_tensor_ring,useAttention,use_modified_ring,window_size,total_epochs,used_epochs,patience,learning_rate,hidden_dim,n_qubits,n_qlayers,test_ratio,total_features,mse,rmse,mae,r2,mape,expressivity_kl
Classic LSTM (WS=4),Classic,0,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.076151542365551,0.2759556891342358,0.24448883533477783,0.024276793003082275,176.78394317626953,
Classic LSTM with Attention (WS=4),Classic,0,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.0807943120598793,0.2842434028431958,0.24988093972206116,-0.035210609436035156,181.22084140777588,
QLSTM standard (WS=4),QLSTM,0,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.08137226104736328,0.2852582357222369,0.24835523962974548,-0.04261577129364014,200.2549171447754,0.07059211650001923
QLSTM standard with Attention (WS=4),QLSTM,0,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.041255317628383636,0.20311405079015002,0.16932833194732666,0.47139912843704224,106.01757764816284,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=4),TensorRing,1,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.07989145070314407,0.2826507574784545,0.24767403304576874,-0.023642301559448242,194.49020624160767,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=4),TensorRing,1,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.03808032348752022,0.19514180353660826,0.15911293029785156,0.5120800733566284,118.78671646118164,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=4),TensorRing,2,False,standard,4,100,100,5,0.001,4,4,2,0.3,5,0.07860908657312393,0.28037312027568534,0.2465524673461914,-0.007211565971374512,189.5647406578064,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=4),TensorRing,2,True,standard,4,100,100,5,0.001,4,4,2,0.3,5,0.07604445517063141,0.27576159118091736,0.24541613459587097,0.025648891925811768,168.88855695724487,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=4),TensorRing,1,False,modified,4,100,100,5,0.001,4,4,1,0.3,5,0.08257640153169632,0.28736109954497374,0.24882660806179047,-0.05804431438446045,204.2640209197998,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=4),TensorRing,1,True,modified,4,100,100,5,0.001,4,4,1,0.3,5,0.06420034915208817,0.25337787818214946,0.2240627259016037,0.1774064302444458,154.96340990066528,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=4),TensorRing,2,False,modified,4,100,100,5,0.001,4,4,2,0.3,5,0.07295875996351242,0.2701087928289496,0.23919999599456787,0.06518560647964478,169.6255087852478,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=4),TensorRing,2,True,modified,4,100,100,5,0.001,4,4,2,0.3,5,0.07714798301458359,0.27775525740223816,0.24547168612480164,0.011509478092193604,177.2098183631897,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=4),TensorRing,1,False,rx,4,100,100,5,0.001,4,4,1,0.3,5,0.0865965262055397,0.29427287711499966,0.25098729133605957,-0.10955393314361572,214.24858570098877,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=4),TensorRing,1,True,rx,4,100,100,5,0.001,4,4,1,0.3,5,0.0799107775092125,0.28268494390259363,0.2506203353404999,-0.023890018463134766,176.07076168060303,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=4),TensorRing,2,False,rx,4,100,100,5,0.001,4,4,2,0.3,5,0.08190609514713287,0.2861924093108216,0.24837718904018402,-0.04945576190948486,202.49080657958984,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=4),TensorRing,2,True,rx,4,100,100,5,0.001,4,4,2,0.3,5,0.06761009246110916,0.2600194078547006,0.23034319281578064,0.1337175965309143,148.7055778503418,0.07688683515604205
Classic LSTM (WS=16),Classic,0,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.0896797627210617,0.2994657955778284,0.2525689899921417,-0.14977514743804932,220.37150859832764,
Classic LSTM with Attention (WS=16),Classic,0,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.06926290690898895,0.2631784696911754,0.23294951021671295,0.11198735237121582,152.78699398040771,
QLSTM standard (WS=16),QLSTM,0,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.08031052350997925,0.2833911140279089,0.24806928634643555,-0.029652953147888184,195.490300655365,0.07059211650001923
QLSTM standard with Attention (WS=16),QLSTM,0,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.07128212600946426,0.2669871270482235,0.23681499063968658,0.08609908819198608,163.38095664978027,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=16),TensorRing,1,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.08032383769750595,0.2834146038889068,0.24736228585243225,-0.029823660850524902,197.13772535324097,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=16),TensorRing,1,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.0740097239613533,0.2720472825840268,0.2411661595106125,0.05112886428833008,161.75206899642944,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=16),TensorRing,2,False,standard,16,100,100,5,0.001,4,4,2,0.3,5,0.07598339021205902,0.2756508483789938,0.24409250915050507,0.02582472562789917,173.21819067001343,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=16),TensorRing,2,True,standard,16,100,100,5,0.001,4,4,2,0.3,5,0.07514706999063492,0.2741296590860517,0.24269285798072815,0.03654712438583374,162.55156993865967,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=16),TensorRing,1,False,modified,16,100,100,5,0.001,4,4,1,0.3,5,0.07534075528383255,0.2744827048901853,0.24298647046089172,0.034063875675201416,175.05325078964233,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=16),TensorRing,1,True,modified,16,100,100,5,0.001,4,4,1,0.3,5,0.08192183077335358,0.2862198993315342,0.2475075125694275,-0.05031144618988037,187.23907470703125,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=16),TensorRing,2,False,modified,16,100,100,5,0.001,4,4,2,0.3,5,0.07403203099966049,0.27208827795342544,0.2406311333179474,0.05084282159805298,174.4887113571167,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=16),TensorRing,2,True,modified,16,100,100,5,0.001,4,4,2,0.3,5,0.07497993111610413,0.27382463569975607,0.24272023141384125,0.03868991136550903,170.30444145202637,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=16),TensorRing,1,False,rx,16,100,100,5,0.001,4,4,1,0.3,5,0.07789111882448196,0.27908980422882157,0.24760976433753967,0.0013659000396728516,175.1176357269287,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=16),TensorRing,1,True,rx,16,100,100,5,0.001,4,4,1,0.3,5,0.06217172369360924,0.24934258299297624,0.217638298869133,0.2029026746749878,138.17918300628662,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=16),TensorRing,2,False,rx,16,100,100,5,0.001,4,4,2,0.3,5,0.07782385498285294,0.27896927247073816,0.24756358563899994,0.002228260040283203,173.46481084823608,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=16),TensorRing,2,True,rx,16,100,100,5,0.001,4,4,2,0.3,5,0.07259359955787659,0.26943199431002357,0.2393341362476349,0.06928485631942749,160.2623701095581,0.07688683515604205

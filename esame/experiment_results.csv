name,modelType,num_layer_tensor_ring,useAttention,use_modified_ring,window_size,total_epochs,used_epochs,patience,learning_rate,hidden_dim,n_qubits,n_qlayers,test_ratio,total_features,mse,rmse,mae,r2,mape,expressivity_kl
Classic LSTM (WS=4),Classic,0,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.076151542365551,0.2759556891342358,0.24448883533477783,0.024276793003082275,176.78394317626953,
Classic LSTM with Attention (WS=4),Classic,0,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.0807943120598793,0.2842434028431958,0.24988093972206116,-0.035210609436035156,181.22084140777588,
QLSTM standard (WS=4),QLSTM,0,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.08137226104736328,0.2852582357222369,0.24835523962974548,-0.04261577129364014,200.2549171447754,0.07059211650001923
QLSTM standard with Attention (WS=4),QLSTM,0,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.041255317628383636,0.20311405079015002,0.16932833194732666,0.47139912843704224,106.01757764816284,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=4),TensorRing,1,False,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.07989145070314407,0.2826507574784545,0.24767403304576874,-0.023642301559448242,194.49020624160767,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=4),TensorRing,1,True,standard,4,100,100,5,0.001,4,4,1,0.3,5,0.03808032348752022,0.19514180353660826,0.15911293029785156,0.5120800733566284,118.78671646118164,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=4),TensorRing,2,False,standard,4,100,100,5,0.001,4,4,2,0.3,5,0.07860908657312393,0.28037312027568534,0.2465524673461914,-0.007211565971374512,189.5647406578064,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=4),TensorRing,2,True,standard,4,100,100,5,0.001,4,4,2,0.3,5,0.07604445517063141,0.27576159118091736,0.24541613459587097,0.025648891925811768,168.88855695724487,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=4),TensorRing,1,False,modified,4,100,100,5,0.001,4,4,1,0.3,5,0.08257640153169632,0.28736109954497374,0.24882660806179047,-0.05804431438446045,204.2640209197998,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=4),TensorRing,1,True,modified,4,100,100,5,0.001,4,4,1,0.3,5,0.06420034915208817,0.25337787818214946,0.2240627259016037,0.1774064302444458,154.96340990066528,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=4),TensorRing,2,False,modified,4,100,100,5,0.001,4,4,2,0.3,5,0.07295875996351242,0.2701087928289496,0.23919999599456787,0.06518560647964478,169.6255087852478,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=4),TensorRing,2,True,modified,4,100,100,5,0.001,4,4,2,0.3,5,0.07714798301458359,0.27775525740223816,0.24547168612480164,0.011509478092193604,177.2098183631897,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=4),TensorRing,1,False,rx,4,100,100,5,0.001,4,4,1,0.3,5,0.0865965262055397,0.29427287711499966,0.25098729133605957,-0.10955393314361572,214.24858570098877,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=4),TensorRing,1,True,rx,4,100,100,5,0.001,4,4,1,0.3,5,0.0799107775092125,0.28268494390259363,0.2506203353404999,-0.023890018463134766,176.07076168060303,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=4),TensorRing,2,False,rx,4,100,100,5,0.001,4,4,2,0.3,5,0.08190609514713287,0.2861924093108216,0.24837718904018402,-0.04945576190948486,202.49080657958984,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=4),TensorRing,2,True,rx,4,100,100,5,0.001,4,4,2,0.3,5,0.06761009246110916,0.2600194078547006,0.23034319281578064,0.1337175965309143,148.7055778503418,0.07688683515604205
Classic LSTM (WS=16),Classic,0,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.0896797627210617,0.2994657955778284,0.2525689899921417,-0.14977514743804932,220.37150859832764,
Classic LSTM with Attention (WS=16),Classic,0,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.06926290690898895,0.2631784696911754,0.23294951021671295,0.11198735237121582,152.78699398040771,
QLSTM standard (WS=16),QLSTM,0,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.08031052350997925,0.2833911140279089,0.24806928634643555,-0.029652953147888184,195.490300655365,0.07059211650001923
QLSTM standard with Attention (WS=16),QLSTM,0,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.07128212600946426,0.2669871270482235,0.23681499063968658,0.08609908819198608,163.38095664978027,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=16),TensorRing,1,False,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.08032383769750595,0.2834146038889068,0.24736228585243225,-0.029823660850524902,197.13772535324097,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=16),TensorRing,1,True,standard,16,100,100,5,0.001,4,4,1,0.3,5,0.0740097239613533,0.2720472825840268,0.2411661595106125,0.05112886428833008,161.75206899642944,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=16),TensorRing,2,False,standard,16,100,100,5,0.001,4,4,2,0.3,5,0.07598339021205902,0.2756508483789938,0.24409250915050507,0.02582472562789917,173.21819067001343,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=16),TensorRing,2,True,standard,16,100,100,5,0.001,4,4,2,0.3,5,0.07514706999063492,0.2741296590860517,0.24269285798072815,0.03654712438583374,162.55156993865967,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=16),TensorRing,1,False,modified,16,100,100,5,0.001,4,4,1,0.3,5,0.07534075528383255,0.2744827048901853,0.24298647046089172,0.034063875675201416,175.05325078964233,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=16),TensorRing,1,True,modified,16,100,100,5,0.001,4,4,1,0.3,5,0.08192183077335358,0.2862198993315342,0.2475075125694275,-0.05031144618988037,187.23907470703125,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=16),TensorRing,2,False,modified,16,100,100,5,0.001,4,4,2,0.3,5,0.07403203099966049,0.27208827795342544,0.2406311333179474,0.05084282159805298,174.4887113571167,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=16),TensorRing,2,True,modified,16,100,100,5,0.001,4,4,2,0.3,5,0.07497993111610413,0.27382463569975607,0.24272023141384125,0.03868991136550903,170.30444145202637,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=16),TensorRing,1,False,rx,16,100,100,5,0.001,4,4,1,0.3,5,0.07789111882448196,0.27908980422882157,0.24760976433753967,0.0013659000396728516,175.1176357269287,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=16),TensorRing,1,True,rx,16,100,100,5,0.001,4,4,1,0.3,5,0.06217172369360924,0.24934258299297624,0.217638298869133,0.2029026746749878,138.17918300628662,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=16),TensorRing,2,False,rx,16,100,100,5,0.001,4,4,2,0.3,5,0.07782385498285294,0.27896927247073816,0.24756358563899994,0.002228260040283203,173.46481084823608,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=16),TensorRing,2,True,rx,16,100,100,5,0.001,4,4,2,0.3,5,0.07259359955787659,0.26943199431002357,0.2393341362476349,0.06928485631942749,160.2623701095581,0.07688683515604205
Classic LSTM (WS=4),Classic,0,False,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.06265285611152649,0.2503055255313524,0.2209072709083557,0.19723427295684814,150.82898139953613,
Classic LSTM with Attention (WS=4),Classic,0,True,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.043413013219833374,0.20835789694617618,0.17182417213916779,0.4437527656555176,136.6207242012024,
QLSTM standard (WS=4),QLSTM,0,False,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.07380077987909317,0.2716629895276373,0.24037131667137146,0.05439692735671997,175.71277618408203,0.07059211650001923
QLSTM standard with Attention (WS=4),QLSTM,0,True,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.01748206466436386,0.1322197589786181,0.09609948843717575,0.7760037779808044,46.90117537975311,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=4),TensorRing,1,False,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.07519154995679855,0.27421077651470693,0.24304306507110596,0.03657710552215576,173.59222173690796,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=4),TensorRing,1,True,standard,4,250,250,5,0.001,4,4,1,0.3,5,0.01916750706732273,0.13844676618586196,0.101709745824337,0.7544083595275879,53.97660732269287,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=4),TensorRing,2,False,standard,4,250,250,5,0.001,4,4,2,0.3,5,0.06929358094930649,0.2632367393608014,0.2318391650915146,0.1121472716331482,171.04331254959106,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=4),TensorRing,2,True,standard,4,250,250,5,0.001,4,4,2,0.3,5,0.049799706786870956,0.22315847908352252,0.1892315149307251,0.36192065477371216,124.13277626037598,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=4),TensorRing,1,False,modified,4,250,250,5,0.001,4,4,1,0.3,5,0.0685880109667778,0.261893128903333,0.23010045289993286,0.12118768692016602,172.14728593826294,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=4),TensorRing,1,True,modified,4,250,250,5,0.001,4,4,1,0.3,5,0.02169669046998024,0.1472979649213805,0.11293187737464905,0.7220021486282349,68.78894567489624,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=4),TensorRing,2,False,modified,4,250,250,5,0.001,4,4,2,0.3,5,0.04255332425236702,0.20628457104778103,0.17250296473503113,0.4547678828239441,121.98934555053711,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=4),TensorRing,2,True,modified,4,250,250,5,0.001,4,4,2,0.3,5,0.022449437528848648,0.1498313636354173,0.11300931125879288,0.7123572826385498,66.06160402297974,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=4),TensorRing,1,False,rx,4,250,250,5,0.001,4,4,1,0.3,5,0.07385989278554916,0.2717717659830564,0.23961645364761353,0.05363947153091431,178.45076322555542,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=4),TensorRing,1,True,rx,4,250,250,5,0.001,4,4,1,0.3,5,0.07832200080156326,0.27986068105677736,0.24859710037708282,-0.0035331249237060547,174.2190718650818,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=4),TensorRing,2,False,rx,4,250,250,5,0.001,4,4,2,0.3,5,0.07252933830022812,0.2693127147021249,0.23725475370883942,0.07068777084350586,176.86219215393066,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=4),TensorRing,2,True,rx,4,250,250,5,0.001,4,4,2,0.3,5,0.024748606607317924,0.1573168986705431,0.12011732906103134,0.682898223400116,69.57717537879944,0.07688683515604205
Classic LSTM (WS=16),Classic,0,False,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.07448329031467438,0.27291626978741,0.24007725715637207,0.04505729675292969,183.18816423416138,
Classic LSTM with Attention (WS=16),Classic,0,True,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.03414933383464813,0.18479538369409593,0.14673006534576416,0.562174916267395,91.0770058631897,
QLSTM standard (WS=16),QLSTM,0,False,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.07599494606256485,0.27567180861046503,0.24405446648597717,0.02567654848098755,176.84637308120728,0.07059211650001923
QLSTM standard with Attention (WS=16),QLSTM,0,True,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.05005151778459549,0.22372196536012168,0.18410374224185944,0.3582945466041565,120.18376588821411,0.07059211650001923
QLSTM Tensor Ring 1 layer (WS=16),TensorRing,1,False,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.07028200477361679,0.2651075343584501,0.23388154804706573,0.09892153739929199,171.5198278427124,0.14158152741140898
QLSTM Tensor Ring 1 layer with Attention (WS=16),TensorRing,1,True,standard,16,250,250,5,0.001,4,4,1,0.3,5,0.04008316248655319,0.2002077982660845,0.16079366207122803,0.4860978126525879,100.35330057144165,0.14158152741140898
QLSTM Tensor Ring 2 layers (WS=16),TensorRing,2,False,standard,16,250,250,5,0.001,4,4,2,0.3,5,0.050500549376010895,0.224723272884699,0.1913694590330124,0.3525375723838806,144.46587562561035,0.06990799766869593
QLSTM Tensor Ring 2 layers with Attention (WS=16),TensorRing,2,True,standard,16,250,250,5,0.001,4,4,2,0.3,5,0.0683751031756401,0.2614863345868004,0.23119674623012543,0.12336981296539307,152.58550643920898,0.06990799766869593
QLSTM Tensor Ring Modified 1 layer (WS=16),TensorRing,1,False,modified,16,250,250,5,0.001,4,4,1,0.3,5,0.048622407019138336,0.2205048911456123,0.18882282078266144,0.37661707401275635,138.46837282180786,0.17456853316354154
QLSTM Tensor Ring Modified 1 layer with Attention (WS=16),TensorRing,1,True,modified,16,250,250,5,0.001,4,4,1,0.3,5,0.048150815069675446,0.21943293980092288,0.17867745459079742,0.3826633095741272,129.7671914100647,0.17456853316354154
QLSTM Tensor Ring Modified 2 layers (WS=16),TensorRing,2,False,modified,16,250,250,5,0.001,4,4,2,0.3,5,0.05019008368253708,0.224031434585723,0.1926831603050232,0.356518030166626,142.02806949615479,0.0011983784068038787
QLSTM Tensor Ring Modified 2 layers with Attention (WS=16),TensorRing,2,True,modified,16,250,250,5,0.001,4,4,2,0.3,5,0.04345375671982765,0.208455646888799,0.17133308947086334,0.44288378953933716,114.77413177490234,0.0011983784068038787
QLSTM Tensor Ring RX 1 layer (WS=16),TensorRing,1,False,rx,16,250,250,5,0.001,4,4,1,0.3,5,0.07050146162509918,0.26552111333206474,0.23440015316009521,0.09610795974731445,167.08111763000488,0.06999039655847243
QLSTM Tensor Ring RX 1 layer with Attention (WS=16),TensorRing,1,True,rx,16,250,250,5,0.001,4,4,1,0.3,5,0.041158102452754974,0.20287459784989095,0.16258110105991364,0.4723162055015564,101.29131078720093,0.06999039655847243
QLSTM Tensor Ring RX 2 layers (WS=16),TensorRing,2,False,rx,16,250,250,5,0.001,4,4,2,0.3,5,0.07286703586578369,0.2699389484046044,0.23910047113895416,0.06577920913696289,170.38477659225464,0.07688683515604205
QLSTM Tensor Ring RX 2 layers with Attention (WS=16),TensorRing,2,True,rx,16,250,250,5,0.001,4,4,2,0.3,5,0.050110168755054474,0.2238530070270544,0.18863266706466675,0.35754263401031494,126.01538896560669,0.07688683515604205
